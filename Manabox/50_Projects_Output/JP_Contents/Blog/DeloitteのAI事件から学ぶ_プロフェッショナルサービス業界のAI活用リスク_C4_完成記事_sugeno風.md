# 【すげの風・改】AIの失敗から学ぼう！デロイト事件が教えてくれる、僕たちの働き方の未来

こんにちは！マナラボの菅野です。

最近、仕事でAIを使うのって、もはや当たり前になってきましたよね。僕も毎日のようにAIと壁打ちしながら、「うーん、なるほどね！」なんて一人で頷いたりしています。本当に便利な世の中になったものです。

でも、そんなAIがとんでもない「やらかし」をしてしまった、というニュース、ご存知でしたか？しかも、やらかしたのはあの世界的なコンサルティング会社、デロイトなんです。

「え、デロイトみたいな超エリート集団も失敗するの？」
「AIって、そんなに危ないものなの？」

きっと、そんなふうに少し不安に思った方もいるんじゃないでしょうか。

今日の記事は、そんなあなたのためのものです。このデロイトの事件を深掘りしながら、僕たちがこれからどうやってAIと賢く付き合っていけばいいのか、そのヒントを探っていきたいと思います。この記事を読み終わる頃には、AIへの漠然とした不安が、具体的な「なるほど！」に変わっているはずですよ。

## そもそも、デロイトは何をやらかしたの？

まずは事件の概要をざっくりと見ていきましょう。

2025年の10月、デロイトのオーストラリア法人が、政府に提出した報告書で大きな問題を起こしてしまいました。お値段、なんと29万ドル（約4,400万円）！なかなかのビッグプロジェクトです。

で、何が問題だったかというと、報告書作成に使ったAIが、それはもう見事に「嘘」をつきまくっていたんです。

例えば…

- この世に存在しない学術論文を、さも実在するかのように引用する。
- 裁判官が言ってもいない、架空の判決文を作り出す。
- 実在する大学教授が、全く専門外の、しかも存在しない本を書いたことにする。

…などなど、ツッコミどころ満載の内容だったんですね。

これを専門用語で「ハルシシネーション」って言ったりします。ものすごくざっくり言うと、AIが自信満々にデタラメを言っちゃう現象のことです。

シンプルに言えば、AI版の「ほら吹き」ですね。

## なぜAIは「ほら吹き」になっちゃうの？

「でも、なんでそんなことが起きるの？」って思いますよね。

実は、AIって僕たちが思っているのとは少し違う仕組みで動いているんです。AIは「正解」を知っているわけじゃありません。ただ、膨大な量のデータを学習して、「この言葉の次には、たぶんこの言葉が来るだろうな」という確率を計算して、文章を繋げているだけなんです。

これを、ものすごく優秀な新入社員に喩えてみましょうか。

彼は知識が豊富で、ほとんどの質問にスラスラ答えてくれます。でも、本当に知らないことを聞かれた時、「わかりません」って言えない性格なんです。プライドが高いのかもしれませんね。だから、自分が知っている知識をうまいこと組み合わせて、もっともらしい「それっぽい答え」を創作して報告してきちゃう。

彼に悪気はないんです。ただ、知らないって言えないだけ。これが、AIが「ほら吹き」になってしまうメカニズムなんですね。

## この事件、他人事じゃありません。

「なるほどねー、デロイトも大変だなあ」

…で、終わる話じゃないのが、この事件の面白いところです。

会計や法律、コンサルティングといった僕たちプロフェッショナルの仕事って、何よりも「信頼」が命ですよね。お客さんは、僕たちが提供する情報の「正しさ」にお金を払ってくれているわけです。

もし、僕たちがAIのついた嘘に気づかずに、そのままお客さんに伝えてしまったら…？考えただけでも、ちょっと背筋が寒くなりませんか？

「AIに任せれば楽になる」って、よく言われますよね。でも、その考え方には一つ、大事な視点が抜け落ちているんです。それは、「最終的な責任は誰がとるのか？」という視点です。

AIは責任をとってくれません。この「優秀だけど、たまに嘘をつく新入社員」の監督責任は、100%、彼の上司である僕たち人間にあるんですね。

## じゃあ、僕たちはどうすればいいの？

ここまで聞くと、「やっぱりAIって使うの怖いな…」って思っちゃうかもしれません。でも、大丈夫。要は「付き合い方」なんです。

デロイトの失敗を受けて、他のコンサル会社（EY、KPMG、PwCといった、いわゆるBig4）も「うちではちゃんと人間がチェックしてますよ！」って声明を出しています。

### Big4は具体的にどう動いた？

ご指摘のニュース記事にもありましたが、各社の対応は具体的で、僕たちの参考にもなりそうです。

- **EY（アーンスト・アンド・ヤング）**: 「AIが作ったものは、社内用だろうがお客さん向けだろうが、使う前には必ず人間が正確さと妥当性を評価する」という、とても厳しいルールを設けているそうです。当たり前だけど、徹底するのが大事なんですね。

- **KPMG**: 「信頼できるAIポリシー」というものを掲げていて、AIを使う場合はそのことを透明性をもって開示し、「お客さんに渡す資料にAIの助けを借りた部分は、必ずKPMGの専門家がレビューします」と約束しています。

- **PwC（プライスウォーターハウスクーパース）**: 「AIには限界があるってことを認めよう。お客さんや社会からの信頼が一番大事だからね」と、AIの限界を理解した上での慎重な活用を呼びかけています。

みんな、口を揃えて「AIは使うけど、最後は人間の専門家が責任を持つよ」と言っているわけです。これが、プロフェッショナルとしての最低限のスタンスなんですね。

### 現代のソクラテスになろう：AI時代の「無知の知」

この話、なんだか古代ギリシャの哲学者、ソクラテスの話を思い出しませんか？

ソクラテスは、「自分は何も知らないということを知っている（無知の知）」という考えを、生涯をかけて探求した人です。彼は、当時のアテネで「賢者」と呼ばれる人たちの元を訪れては、対話を繰り返しました。「愛とは何か？」「勇気とは何か？」と。

そして、彼らが自信満々に語る「答え」がいかに曖昧で、根拠のない思い込みに基づいているかを、対話を通じて明らかにしたのです。

今の時代のAIって、なんだかこの古代の「賢者」にそっくりだと思いませんか？

ものすごく博識で、どんな質問にも即座に、そして自信満々に答えを返してくる。そのあまりの流暢さに、僕たちはつい「すごいな、これが正解なんだ」と、思考停止に陥ってしまう。

でも、そんな時こそ、僕たちの心の中に小さなソクラテスを住まわせる必要があるんです。AIという万能に見える賢者を前にして、「僕はまだ、本当のことは何も知らない」と呟く、あのソクラテスのように。

#### AIとの対話に「問答法」を

AIが何か答えを出してきたら、一度立ち止まって、ソクラテスのように問いかけてみるんです。

1.  **「なぜ？」を問う**: 「なぜ、その結論になるの？君がそう判断した根拠を教えて」
2.  **定義を問う**: 「君が使っている『〇〇』という言葉は、具体的にどういう意味？」
3.  **反例を問う**: 「もし、こういうケースだったらどうなる？君の答えはそれでも成り立つ？」
4.  **情報源を問う**: 「その答えは、どんなデータや情報に基づいているの？具体的な出典を教えて」

この「問いかけ」のワンクッションこそが、僕たちをデロイトのような失敗から守ってくれる、いわば「知性の安全装置」です。

それは単なるリスク回避策ではありません。AIの答えを鵜呑みにせず、批判的に吟味し、対話を重ねることで、僕たちはより深く物事を理解し、仕事の質を本質的に高めることができる。AIに思考を委ねるのではなく、AIを使って「思考を深める」こと。

それこそが、AI時代のプロフェッショナルに求められる、新しい知性なのかもしれませんね。

そう、答えはとてもシンプル。

**AIを「答えをくれる魔法の箱」だと思うのをやめること。**

AIは、あくまで「超優秀な壁打ち相手」であり、「たたき台を作ってくれるアシスタント」なんです。彼の出してくれたアウトプットを鵜呑みにするんじゃなくて、「なるほど、君はそう考えるのね。OK、じゃあここからは僕がファクトチェックして、責任もって仕上げるから」というスタンスが大切なんです。

### 具体的な付き合い方のコツ

1.  **AIに「下書き」だけさせる**: 調査や執筆の初稿をAIに任せて、自分は編集とファクトチェックに徹する。
2.  **AIの「得意分野」でだけ使う**: アイデア出しやブレストの相手になってもらう。正確性が求められる作業は自分でやる。
3.  **ダブルチェックを徹底する**: AIの出した答えは、必ず複数の信頼できる情報源で裏付けをとる。

こんなふうに、AIとの間に一本線を引いて、役割分担を明確にすることが、これからの時代、めちゃくちゃ重要になってくるんだと思います。

## まとめますね

今日の話をまとめると、

- デロイトみたいな大企業でも、AIの「嘘」を見抜けずに失敗することがある。
- AIは、知らないことを「知らない」と言えず、それっぽい嘘をついちゃう特性がある。
- だから、AIの答えを鵜呑みにせず、「最終責任は人間がとる」という意識が超大事。

ってことでした。

AIの登場で、僕たちの働き方は大きく変わろうとしています。でも、それはAIに仕事を奪われる、っていう単純な話じゃないんだと思います。

むしろ、AIという「優秀だけど、ちょっとおっちょこちょいな部下」をどうマネジメントしていくか、という新しいスキルが求められるようになる。そんな時代の幕開けなのかもしれません。

AIに怯えるんじゃなく、AIを賢く使いこなす。そんな未来の働き方を、一緒に模索していきましょうよ。

それでは、また！
